name: Scrape New Listings

on:
  schedule:
    # Every hour
    - cron: '0 * * * *'
  workflow_dispatch:
    # Manual trigger with optional parameters
    inputs:
      max_days:
        description: 'Max age of listings in days'
        required: false
        default: '7'
      limit:
        description: 'Max listings per source (leave empty for all)'
        required: false
        default: ''

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: pip install -r requirements.txt
      
      - name: Run scraper
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
        run: |
          if [ -n "${{ github.event.inputs.limit }}" ]; then
            python scraper_encuentra24.py --max-days ${{ github.event.inputs.max_days || '7' }} --limit ${{ github.event.inputs.limit }}
          else
            python scraper_encuentra24.py --max-days ${{ github.event.inputs.max_days || '7' }}
          fi
